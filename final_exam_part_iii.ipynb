{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ongoing-current",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Final Examination (Notebook III)\n",
    "\n",
    "For instructions on how to use TestMyCode (TMC) to test your code and submit it to the server, see <a href=\"https://applied-language-technology.mooc.fi/html/tmc.html\" target=\"blank_\">here</a>.\n",
    "\n",
    "Remember to save this Notebook before testing your code. Press <kbd>Control</kbd>+<kbd>s</kbd> or select the *File* menu and click *Save*.\n",
    "\n",
    "**The maximum number of points for this Notebook is 45.**\n",
    "\n",
    "⚠️ Set the variable `grade` in the cell below to `True` to enable testing. ⚠️\n",
    "\n",
    "The commands `tmc test` and `tmc submit` work only when the `grade` variable has been set to `True`. \n",
    "\n",
    "You can disable testing for some Notebooks to speed up the process before submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9230516",
   "metadata": {
    "deletable": false,
    "test": "grade"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThis Notebook will be graded.\u001b[0m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the value of the variable 'grade' to True to enable testing and submitting\n",
    "grade = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-beverage",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 1. Load CoNLL-U annotated corpora into Python and parse the annotations (15 points)\n",
    "\n",
    "**Prerequisites for this exercise**: None.\n",
    "\n",
    "The directory `data` contains 10 files from the Georgetown University Multilayer Corpus (GUM), which contain annotations in the CoNLL-U format. These files can be identified by the suffix `conllu`.\n",
    "\n",
    "Open each file for reading, read its contents and store the resulting string objects into a list named `annotations`.\n",
    "\n",
    "Use the `conllu` library to parse the CoNLL-U compliant annotations stored in the list `annotations`. Store the resulting lists of *TokenList* objects into a list named `doc_lists`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "centered-buying",
   "metadata": {
    "deletable": false,
    "test": "read_conllu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"doc_lists\" was defined successfully! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"doc_lists\" contains a list! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe list \"doc_lists\" contains TokenList objects! 13 points.\u001b[0m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer below this line. Please enter your entire solution in this cell.\n",
    "import os\n",
    "from conllu import parse\n",
    "\n",
    "# Specify the directory containing the CoNLL-U files\n",
    "data_directory = \"data\"\n",
    "\n",
    "# Initialize a list to store the contents of each CoNLL-U file\n",
    "annotations = []\n",
    "\n",
    "# Initialize a list to store the parsed TokenList objects\n",
    "doc_lists = []\n",
    "\n",
    "# List all files in the data directory with the \".conllu\" suffix\n",
    "conllu_files = [file for file in os.listdir(data_directory) if file.endswith(\".conllu\")]\n",
    "\n",
    "# Loop over each CoNLL-U file\n",
    "for conllu_file in conllu_files:\n",
    "    # Construct the full path to the file\n",
    "    file_path = os.path.join(data_directory, conllu_file)\n",
    "\n",
    "    # Read the contents of the CoNLL-U file\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        conllu_contents = file.read()\n",
    "    \n",
    "    # Append the contents to the 'annotations' list\n",
    "    annotations.append(conllu_contents)\n",
    "\n",
    "    # Parse the CoNLL-U compliant annotations and store the TokenList objects\n",
    "    doc_list = parse(conllu_contents)\n",
    "    doc_lists.append(doc_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-location",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 2. Collect information on discourse unit boundaries (15 points)\n",
    "\n",
    "**Prerequisites for this exercise**: You must have completed exercise 1 in this Notebook. You can use variables defined in exercise 1.\n",
    "\n",
    "Collect information on discourse unit boundaries from the documents stored in `doc_lists`. This information can be found under the `misc` attribute of individual *Token* objects.\n",
    "\n",
    "Create a dictionary named `edu_indices` and populate this dictionary with keys and values. \n",
    "\n",
    "The keys should correspond to the unique identifiers for each document in `doc_lists`, whereas their corresponding values should consist of a list with numbers that give the indices for the *Tokens* that start a new discourse unit. \n",
    "\n",
    "The unique identifiers can be found in the metadata for each *TokenList* object contained in a document.\n",
    "\n",
    "*Tips*: Think how the different objects are organised in `doc_lists` and define nested `for` loops accordingly. Use a counter to track the indices, and think carefully where and when you reset and update the counter. Pay attention to the criteria used to evaluate whether the key `misc` of a *Token* object contains any values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "composed-adelaide",
   "metadata": {
    "deletable": false,
    "test": "disc_bound"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"edu_indices\" was defined successfully! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"edu_indices\" contains a dictionary! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[91mThe dictionary \"edu_indices\" does not contain the expected items.\u001b[0m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer below this line. Please enter your entire solution in this cell.\n",
    "# Create an empty dictionary to store the discourse unit indices\n",
    "edu_indices = {}\n",
    "a=0\n",
    "counter = 0\n",
    "# Loop through each document in doc_lists\n",
    "for doc_list in doc_lists:\n",
    "    for i in doc_list:\n",
    "        for j in i:\n",
    "            if j['misc'] is not None and 'Discourse' in j['misc']:\n",
    "        #print(i.metadata)\n",
    "                a+=1\n",
    "                print(a)\n",
    "                print(j['misc'])\n",
    "                counter += 1\n",
    "                edu_indices[i.metadata['s_type']]=counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6138b91a-7dac-49e3-88c5-108147bb6a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decl': 689, 'frag': 669, 'other': 517, 'sub': 671, 'multiple': 592, 'q': 670}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb29dc61-3101-4d88-8c7b-7ee6553525ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store the discourse unit indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-receiver",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 3. Convert the CoNLL-U annotations into spaCy *Doc* objects (15 points)\n",
    "\n",
    "**Prerequisites for this exercise**: You must have completed exercise 1 in this Notebook. You can use variables defined in exercise 1.\n",
    "\n",
    "Use the `conllu_to_docs` function in spaCy to convert the string objects in the list `annotations` into spaCy *Doc* objects.\n",
    "\n",
    "Because this function creates a new *Doc* object for every 10 sentences defined in the CoNLL-U annotations, create a new *Doc* object and use the `from_docs` method to join the *Doc* objects. \n",
    "\n",
    "Store the resulting *Doc* objects into the list `conllu_docs`.\n",
    "\n",
    "*Tip*: You need to import the spaCy *Doc* class as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "demonstrated-stable",
   "metadata": {
    "deletable": false,
    "test": "convert_doc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"conllu_docs\" was defined successfully! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"conllu_docs\" contains a list! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe list \"conllu_docs\" contains the expected items! 13 points.\u001b[0m"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer below this line. Please enter your entire solution in this cell.\n",
    "import conllu\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize a list to store the resulting Doc objects\n",
    "conllu_docs = []\n",
    "\n",
    "# Loop over each CoNLL-U annotation in the 'annotations' list\n",
    "for annotation in annotations:\n",
    "    # Parse the CoNLL-U annotation using the conllu library\n",
    "    parsed_data = conllu.parse(annotation)\n",
    "    \n",
    "    # Extract the words from the parsed data\n",
    "    words = [token['form'] for sentence in parsed_data for token in sentence]\n",
    "    \n",
    "    # Create a spaCy Doc object from the words\n",
    "    doc = nlp_en(\" \".join(words))\n",
    "    \n",
    "    # Append the Doc object to the list\n",
    "    conllu_docs.append(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f7d41-86b2-4238-b51b-81c14cc06845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
