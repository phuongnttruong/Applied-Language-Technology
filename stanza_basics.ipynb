{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "multiple-majority",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Processing texts using Stanza\n",
    "\n",
    "See the learning materials associated with this exercise <a href=\"https://applied-language-technology.mooc.fi/html/notebooks/part_iii/01_multilingual_nlp.html\" target=\"blank_\">here</a>.\n",
    "\n",
    "For instructions on how to use TestMyCode (TMC) to test your code and submit it to the server, see <a href=\"https://applied-language-technology.mooc.fi/html/tmc.html\" target=\"blank_\">here</a>.\n",
    "\n",
    "Remember to save this Notebook before testing your code. Press <kbd>Control</kbd>+<kbd>s</kbd> or select the *File* menu and click *Save*.\n",
    "\n",
    "**The maximum number of points for this exercise is 25.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-signature",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 1. Import the Stanza library (1 point)\n",
    "\n",
    "Import the Stanza natural language processing library (`stanza`) into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "later-poland",
   "metadata": {
    "deletable": false,
    "test": "import_stanza"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe Stanza library was imported successfully! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer below this line\n",
    "import stanza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-episode",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 2. Initialise a Stanza Pipeline object (5 points)\n",
    "\n",
    "Use the Stanza *Pipeline* class to create a Stanza natural language processing pipeline.\n",
    "\n",
    "Load the default language model for Finnish (`fi`) into the *Pipeline* object. The language model has been downloaded on your server.\n",
    "\n",
    "Assign the resulting *Pipeline* object under the variable `nlp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "considerable-fleet",
   "metadata": {
    "deletable": false,
    "test": "load_model"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"nlp\" was defined successfully! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"nlp\" contains a Stanza Pipeline object! 3 points.\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"nlp\" contains a Pipeline for Finnish! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer below this line\n",
    "nlp = stanza.Pipeline(lang='fi')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-labor",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 3. Feed text to the language model for processing (3 points)\n",
    "\n",
    "The variable `text` contains a few sentences in Finnish.\n",
    "\n",
    "Feed the string object stored under the variable `text` to the language model under `nlp`.\n",
    "\n",
    "Store the resulting Stanza *Document* object under the variable `my_doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "threatened-minute",
   "metadata": {
    "deletable": false,
    "test": "process_text"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"my_doc\" was defined successfully! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"my_doc\" contains a Stanza Document object! 2 points.\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a string object with some text in Finnish\n",
    "text = \"Tässä on yksi esimerkki. Ja tässä on toinen.\"\n",
    "\n",
    "# Write your answer below this line\n",
    "my_doc = nlp(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-engineering",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 4. Get the first sentence in the Stanza *Document* object (3 points)\n",
    "\n",
    "Use the `sentences` attribute to retrieve the first sentence in the Stanza *Document* object under `my_doc`.\n",
    "\n",
    "Assign the first sentence under the variable `my_sent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "weird-telescope",
   "metadata": {
    "deletable": false,
    "test": "get_sent"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"my_sent\" was defined successfully! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"my_sent\" contains a Stanza Sentence object! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"my_sent\" contains the expected objects! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer below this line\n",
    "my_sent = my_doc.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51faf1ae-aab0-4098-b08d-c4528fcb6260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  {\n",
       "    \"id\": 1,\n",
       "    \"text\": \"Tässä\",\n",
       "    \"lemma\": \"tämä\",\n",
       "    \"upos\": \"PRON\",\n",
       "    \"xpos\": \"Pron\",\n",
       "    \"feats\": \"Case=Ine|Number=Sing|PronType=Dem\",\n",
       "    \"head\": 0,\n",
       "    \"deprel\": \"root\",\n",
       "    \"start_char\": 0,\n",
       "    \"end_char\": 5,\n",
       "    \"ner\": \"O\"\n",
       "  },\n",
       "  {\n",
       "    \"id\": 2,\n",
       "    \"text\": \"on\",\n",
       "    \"lemma\": \"olla\",\n",
       "    \"upos\": \"AUX\",\n",
       "    \"xpos\": \"V\",\n",
       "    \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\",\n",
       "    \"head\": 1,\n",
       "    \"deprel\": \"cop\",\n",
       "    \"start_char\": 6,\n",
       "    \"end_char\": 8,\n",
       "    \"ner\": \"O\"\n",
       "  },\n",
       "  {\n",
       "    \"id\": 3,\n",
       "    \"text\": \"yksi\",\n",
       "    \"lemma\": \"yksi\",\n",
       "    \"upos\": \"NUM\",\n",
       "    \"xpos\": \"Num\",\n",
       "    \"feats\": \"Case=Nom|NumType=Card|Number=Sing\",\n",
       "    \"head\": 4,\n",
       "    \"deprel\": \"nummod\",\n",
       "    \"start_char\": 9,\n",
       "    \"end_char\": 13,\n",
       "    \"ner\": \"O\"\n",
       "  },\n",
       "  {\n",
       "    \"id\": 4,\n",
       "    \"text\": \"esimerkki\",\n",
       "    \"lemma\": \"esimerkki\",\n",
       "    \"upos\": \"NOUN\",\n",
       "    \"xpos\": \"N\",\n",
       "    \"feats\": \"Case=Nom|Number=Sing\",\n",
       "    \"head\": 1,\n",
       "    \"deprel\": \"nsubj:cop\",\n",
       "    \"start_char\": 14,\n",
       "    \"end_char\": 23,\n",
       "    \"ner\": \"O\"\n",
       "  },\n",
       "  {\n",
       "    \"id\": 5,\n",
       "    \"text\": \".\",\n",
       "    \"lemma\": \".\",\n",
       "    \"upos\": \"PUNCT\",\n",
       "    \"xpos\": \"Punct\",\n",
       "    \"head\": 1,\n",
       "    \"deprel\": \"punct\",\n",
       "    \"start_char\": 23,\n",
       "    \"end_char\": 24,\n",
       "    \"ner\": \"O\"\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23744b1b-8709-423a-aefe-ec43b96cd4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stanza.models.common.doc.Sentence"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-german",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 5. Convert the Stanza *Sentence* object into a Python dictionary (2 points)\n",
    "\n",
    "Convert the linguistic annotations stored in the Stanza *Sentence* object under the variable `my_sent` into Python dictionaries using the `to_dict()` method.\n",
    "\n",
    "Assign the resulting list of dictionaries under the variable `my_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "continuous-auditor",
   "metadata": {
    "deletable": false,
    "test": "to_dict"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"my_list\" was defined successfully! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"my_list\" contains the expected objects! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer below this line\n",
    "my_list = my_sent.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb177e8f-8b02-47f2-9a05-673a28c41f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'text': 'Tässä',\n",
       "  'lemma': 'tämä',\n",
       "  'upos': 'PRON',\n",
       "  'xpos': 'Pron',\n",
       "  'feats': 'Case=Ine|Number=Sing|PronType=Dem',\n",
       "  'head': 0,\n",
       "  'deprel': 'root',\n",
       "  'start_char': 0,\n",
       "  'end_char': 5,\n",
       "  'ner': 'O'},\n",
       " {'id': 2,\n",
       "  'text': 'on',\n",
       "  'lemma': 'olla',\n",
       "  'upos': 'AUX',\n",
       "  'xpos': 'V',\n",
       "  'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act',\n",
       "  'head': 1,\n",
       "  'deprel': 'cop',\n",
       "  'start_char': 6,\n",
       "  'end_char': 8,\n",
       "  'ner': 'O'},\n",
       " {'id': 3,\n",
       "  'text': 'yksi',\n",
       "  'lemma': 'yksi',\n",
       "  'upos': 'NUM',\n",
       "  'xpos': 'Num',\n",
       "  'feats': 'Case=Nom|NumType=Card|Number=Sing',\n",
       "  'head': 4,\n",
       "  'deprel': 'nummod',\n",
       "  'start_char': 9,\n",
       "  'end_char': 13,\n",
       "  'ner': 'O'},\n",
       " {'id': 4,\n",
       "  'text': 'esimerkki',\n",
       "  'lemma': 'esimerkki',\n",
       "  'upos': 'NOUN',\n",
       "  'xpos': 'N',\n",
       "  'feats': 'Case=Nom|Number=Sing',\n",
       "  'head': 1,\n",
       "  'deprel': 'nsubj:cop',\n",
       "  'start_char': 14,\n",
       "  'end_char': 23,\n",
       "  'ner': 'O'},\n",
       " {'id': 5,\n",
       "  'text': '.',\n",
       "  'lemma': '.',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': 'Punct',\n",
       "  'head': 1,\n",
       "  'deprel': 'punct',\n",
       "  'start_char': 23,\n",
       "  'end_char': 24,\n",
       "  'ner': 'O'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ef9ff",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 6. Collect lemmas from the dictionaries under `my_list` (4 points)\n",
    "\n",
    "Collect the lemmas for each token from the dictionaries in the list `my_list`.\n",
    "\n",
    "Use the `append()` method of a Python list to append the lemmas into the list named `lemmas`.\n",
    "\n",
    "Tip: You need to define a `for` loop to retrieve each lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "705bdd03",
   "metadata": {
    "deletable": false,
    "test": "get_lemmas"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"lemmas\" exists!\u001b[0m"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"lemmas\" contains a list! \u001b[0m"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"lemmas\" contains the expected values! 5 points.\u001b[0m"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a placeholder list for the lemmas\n",
    "lemmas = []\n",
    "\n",
    "# Write your answer below this line\n",
    "for i in my_list:\n",
    "    lemmas.append(i['lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe1a504d-161f-42aa-8c08-7a44c3510f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tämä', 'olla', 'yksi', 'esimerkki', '.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b61bb99",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 7. Import the spacy-stanza library (1 point)\n",
    "\n",
    "Import the spacy-stanza library (`spacy_stanza`) into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b1c26c9",
   "metadata": {
    "deletable": false,
    "test": "import_spacy_stanza"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe spacy-stanza library was imported successfully! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer below this line\n",
    "import spacy_stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3129e",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 8. Load a Stanza language model into spaCy (3 points)\n",
    "\n",
    "Use the spacy-stanza library to load a Stanza language model for Finnish into spaCy.\n",
    "\n",
    "Store the resulting *Language* object under the variable `spacy_fi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "285edbd5",
   "metadata": {
    "deletable": false,
    "test": "load_smodel"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"spacy_fi\" was defined successfully! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe Stanza language model for Finnish was loaded successfully into spaCy! 2 points.\u001b[0m"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer below this line\n",
    "spacy_fi = spacy_stanza.load_pipeline(name='fi')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c792c84",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 9. Feed text to the spaCy language model (3 points)\n",
    "\n",
    "Provide the text stored under the variable `text` as input to the language model under `spacy_fi`.\n",
    "\n",
    "Store the resulting *Doc* object under the variable `doc_fi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bab52810",
   "metadata": {
    "deletable": false,
    "test": "process_text_2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"doc_fi\" was defined successfully! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"doc_fi\" contains a spaCy Doc object! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[TMC]\u001b[0m \u001b[92mThe variable \"doc_fi\" contains the expected value ! 1 point.\u001b[0m"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer below this line\n",
    "doc_fi =spacy_fi(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca4a46-d02f-4056-ace9-d869c1fd0c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
