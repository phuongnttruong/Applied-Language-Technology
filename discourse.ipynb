{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "altered-jacob",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Discourse-level annotations\n",
    "\n",
    "See the learning materials associated with this exercise <a href=\"https://applied-language-technology.mooc.fi/html/notebooks/part_iii/06_text_linguistics.html\" target=\"blank_\">here</a>.\n",
    "\n",
    "For instructions on how to use TestMyCode (TMC) to test your code and submit it to the server, see <a href=\"https://applied-language-technology.mooc.fi/html/tmc.html\" target=\"blank_\">here</a>.\n",
    "\n",
    "Remember to save this Notebook before testing your code. Press <kbd>Control</kbd>+<kbd>s</kbd> or select the *File* menu and click *Save*.\n",
    "\n",
    "**The maximum number of points for this exercise is 25.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-stevens",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 1. Import the *conllu* library (1 points)\n",
    "\n",
    "Import the *conllu* library (`conllu`) into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hollywood-defeat",
   "metadata": {
    "deletable": false,
    "test": "import_conllu"
   },
   "outputs": [],
   "source": [
    "# Write your answer below this line\n",
    "import conllu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-thumb",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 2. Load CoNLL-U annotations from file (3 points)\n",
    "\n",
    "A directory named `data` in the exercise directory contains a file named `GUM_interview_gaming.conllu`. The file contains CoNLLU-compliant annotations.\n",
    "\n",
    "Load this file into Python and read its contents.\n",
    "\n",
    "Assign the resulting string object under the variable `ann`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "transsexual-setup",
   "metadata": {
    "deletable": false,
    "test": "load_text"
   },
   "outputs": [],
   "source": [
    "# Write your answer below this line\n",
    "with open('data/GUM_interview_gaming.conllu', mode=\"r\", encoding=\"utf-8\") as data:\n",
    "    \n",
    "    # Read the file contents and assign under 'annotations'\n",
    "    ann = data.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-settlement",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 3. Parse CoNLL-U annotations (3 points)\n",
    "\n",
    "Use the `conllu` library to parse the annotations in the string object `ann`.\n",
    "\n",
    "Store the result under the variable `c_ann`.\n",
    "\n",
    "*Tip*: In case of weird error messages, it's always a good idea to reset the kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "broad-interface",
   "metadata": {
    "deletable": false,
    "test": "parse_ann"
   },
   "outputs": [],
   "source": [
    "# Write your answer below this line\n",
    "c_ann = conllu.parse(ann)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-ozone",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 4. Examine CoNLL-U annotations (3 points)\n",
    "\n",
    "Get the third *TokenList* object in the list `c_ann`. Then retrieve the universal part-of-speech tag for the *Token* at index 5 of the *TokenList* object.\n",
    "\n",
    "Assign the tag under the variable `tag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "surrounded-audience",
   "metadata": {
    "deletable": false,
    "test": "examine_ann"
   },
   "outputs": [],
   "source": [
    "# Write your answer below this line\n",
    "tag=c_ann[2][5]['upos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81c259c4-8e46-4fb7-8a12-76ba49a92302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PUNCT'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-piano",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 5. Collect information on sentence mood (5 points)\n",
    "\n",
    "Each *TokenList* object in the list `c_ann` contains information on the grammatical mood of the sentence.\n",
    "\n",
    "This information is stored under the key `s_type` of the `metadata` attribute.\n",
    "\n",
    "Collect this information for every *TokenList* object into a list named `moods`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "economic-click",
   "metadata": {
    "deletable": false,
    "test": "get_mood"
   },
   "outputs": [],
   "source": [
    "# Write your answer below this line\n",
    "# Initialize an empty list to store the moods\n",
    "moods = []\n",
    "\n",
    "# Iterate through each TokenList object in the list c_ann\n",
    "for token_list in c_ann:\n",
    "    # Check if the 's_type' key exists in the metadata attribute\n",
    "    if 's_type' in token_list.metadata:\n",
    "        # Append the value of 's_type' to the moods list\n",
    "        moods.append(token_list.metadata['s_type'])\n",
    "    else:\n",
    "        # Handle the case where 's_type' is not present (e.g., set it to None)\n",
    "        moods.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-inspection",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 6. Collect information from the CoNLL-U annotations (5 points)\n",
    "\n",
    "The following code collects information from the CoNLL-U annotations stored under the list `c_ann`.\n",
    "\n",
    "Finish the code by collecting the form of each *Token* into the list `words` and its universal part-of-speech tag into the list `pos`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accompanied-tucson",
   "metadata": {
    "deletable": false,
    "test": "get_pos"
   },
   "outputs": [],
   "source": [
    "# Create placeholder lists\n",
    "words, pos, spaces, sents = [], [], [], []\n",
    "\n",
    "# Collect words, spaces and sentence starts from the TokenList\n",
    "# objects stored in the list 'ann'.\n",
    "for sentence in c_ann:\n",
    "    \n",
    "    # Track sentence starts\n",
    "    start_sent = True\n",
    "    \n",
    "    # Loop over tokens\n",
    "    for token in sentence:\n",
    "        \n",
    "        # Check if this Token starts a sentence\n",
    "        if start_sent:\n",
    "            \n",
    "            sents.append(True)\n",
    "            start_sent = False\n",
    "        \n",
    "        # Otherwise append False\n",
    "        else:\n",
    "            \n",
    "            sents.append(False)\n",
    "            \n",
    "        # Check if the Token is not followed by a space\n",
    "        if token['misc'] is not None and 'SpaceAfter' in token['misc'] and token['misc']['SpaceAfter'] == 'No':\n",
    "            \n",
    "            spaces.append(False)\n",
    "        \n",
    "        # Otherwise append True\n",
    "        else:\n",
    "            \n",
    "            spaces.append(True)\n",
    "        \n",
    "        # Write your answer below this line. Remember to indent your code!\n",
    "        words.append(token['form'])\n",
    "        pos.append(token['upostag'])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a94ddbc-1977-4675-9e6a-57b4f53fae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717\n",
      "717\n",
      "717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "717"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(spaces))\n",
    "print(len(words))\n",
    "print(len(pos))\n",
    "len(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-trademark",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## 7. Create a spaCy *Doc* object manually (5 points)\n",
    "\n",
    "Use the information collected into the lists `words`, `pos`, `spaces` and `sents` to create a spaCy *Doc* object manually.\n",
    "\n",
    "Assign the resulting *Doc* object under the variable `doc`.\n",
    "\n",
    "*Tip*: You need to provide inputs to the following variables: `vocab`, `words`, `pos`, `spaces` and `sent_starts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "artistic-prairie",
   "metadata": {
    "deletable": false,
    "test": "create_doc"
   },
   "outputs": [],
   "source": [
    "# Import the spaCy library and the Doc class\n",
    "from spacy.tokens import Doc\n",
    "import spacy\n",
    "\n",
    "# Load a small language model for English\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Write your answer below this line\n",
    "doc = Doc(vocab=nlp.vocab, \n",
    "          words=words,\n",
    "          pos = pos,\n",
    "          spaces=spaces,\n",
    "          sent_starts=sents\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea3cdda-597d-4ec6-bcbd-a9538e91b22b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
